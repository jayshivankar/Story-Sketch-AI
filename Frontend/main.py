# Frontend/main.py
import streamlit as st
from audiorecorder import audiorecorder
import io

from api import transcribe_audio  # ‚úÖ uses separate request logic

st.set_page_config(page_title="üé® StorySketch", layout="centered")
st.title("üé® StorySketch")
st.caption("üöÄ Speak or type your story ‚Äî Let AI illustrate and narrate it!")

# Step 1: User inputs
user_text = st.text_input("üìù Or type your story idea:", placeholder="A robot finds treasure on the moon...")
st.markdown("üé§ Or record your story prompt:")
audio = audiorecorder("Click to record", "Recording...")

transcript = None
final_prompt = None

# Step 2: Handle audio
if len(audio) > 0:
    buffer = io.BytesIO()
    audio.export(buffer, format="wav")
    wav_bytes = buffer.getvalue()

    st.audio(wav_bytes, format="audio/wav")

    with st.spinner("‚è≥ Transcribing your voice with Groq Whisper..."):
        transcript, error = transcribe_audio(wav_bytes)

        if transcript:
            st.success("‚úÖ Transcription complete!")
            st.markdown(f"**üìú Transcript (from audio):** {transcript}")
        else:
            st.error("‚ùå Transcription failed")
            st.json(error)

# Step 3: Determine final prompt
if user_text.strip():
    final_prompt = user_text.strip()
elif transcript:
    final_prompt = transcript


if __name__ == "__main__":
    print(final_prompt)


