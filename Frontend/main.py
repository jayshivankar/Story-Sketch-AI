# Frontend/main.py
import streamlit as st
from audiorecorder import audiorecorder
import io

from api import transcribe_audio  # âœ… uses separate request logic

st.set_page_config(page_title="ğŸ¨ StorySketch", layout="centered")
st.title("ğŸ¨ StorySketch")
st.caption("ğŸš€ Speak or type your story â€” Let AI illustrate and narrate it!")

# Step 1: User inputs
user_text = st.text_input("ğŸ“ Or type your story idea:", placeholder="A robot finds treasure on the moon...")
st.markdown("ğŸ¤ Or record your story prompt:")
audio = audiorecorder("Click to record", "Recording...")

transcript = None
final_prompt = None

# Step 2: Handle audio
if len(audio) > 0:
    buffer = io.BytesIO()
    audio.export(buffer, format="wav")
    wav_bytes = buffer.getvalue()

    st.audio(wav_bytes, format="audio/wav")

    with st.spinner("â³ Transcribing your voice with Groq Whisper..."):
        transcript, error = transcribe_audio(wav_bytes)

        if transcript:
            st.success("âœ… Transcription complete!")
            st.markdown(f"**ğŸ“œ Transcript (from audio):** {transcript}")
        else:
            st.error("âŒ Transcription failed")
            st.json(error)

# Step 3: Determine final prompt
if user_text.strip():
    final_prompt = user_text.strip()
elif transcript:
    final_prompt = transcript

# Step 4: Display prompt & prepare next steps
if final_prompt:
    st.markdown("---")
    st.markdown("### âœ… Final Prompt to Use:")
    st.markdown(f"> {final_prompt}")

    # col1, col2, col3 = st.columns(3)
    # with col1:
    #     st.button("ğŸ§  Generate Story", disabled=True)
    # with col2:
    #     st.button("ğŸ¨ Generate Images", disabled=True)
    # with col3:
    #     st.button("ğŸ”Š Generate Narration", disabled=True)
    #
    # st.info("ğŸ”§ These features will be enabled in the next step.")
